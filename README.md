# NUWEST: NNSA-University Workshop on Exascale Simulation Technologies 
## Thursday January 18, 2024 in Albuquerque at the Crowne Plaza

The NNSA-University Workshop on Exascale Simulation Technologies (NUWEST) will
be held on **Thursday January 18, 2024** in Albuquerque at the Crowne Plaza.  The
overarching goal of NUWEST is to share ideas on technologies for facilitating
exascale predictive science, by showcasing available technologies, identifying
challenges, and initiating further collaborations with NNSA laboratory efforts.

The workshop will highlight technologies from [PSAAPIII](https://psaap.llnl.gov/)
centers.  The schedule is below.

The workshop is designed to encourage hands-on demonstration of technologies
used in and employed across the centers in their predictive simulations, with a
goal of encouraging wider adoption of the key concepts in the technology itself
or direct use of the underlying software.

If you have questions or if you are interested in registering to attend, please contact
Luke Olson (`lukeo` at `illinois.edu`) or Courtney McLearnin (`cmcleari` at `illinois.edu`).

#### Quicklinks:

- Schedule: <https://illinois-ceesd.github.io/nuwest>
- NUWEST git repository: <https://github.com/illinois-ceesd/nuwest>
- Slack: TBD 

## Schedule

| Time |  Title/Speaker | Room | Links |
| ---- | -------------- | ---- | ----- |
| 0800 – 815 | **Introduction** <br/> Luke Olson, University of Illinois Urbana-Champaign | Ballroom | [nuwest.pdf](./extra/nuwest.pdf) |
| 0815 – 0930 | **Keynotes** | Ballroom | |
|             | Success through Community Building – A Kokkos Story<br/> Christian Trott, Sandia National Laboratories | | |
|             | Getting to adoption: Lessons from MPI and PETSc<br/>Bill Gropp University of Illinois Urbana-Champaign<br/>abstract: Many software projects measure their success by the number of users that adopt that software for their work. Few succeed in getting significant adoption. What do these two successful projects tell us about getting an HPC tool to adoption by the community? This talk will review the history of two different projects: PETSc, a software library designed to support the development of applications to solve PDEs in parallel, and MPI, a specification (not a library) for communicating between processes. The importance of both the design and implementation of the projects as well as the marketing and support are discusses, and lessons for other HPC projects are discussed.| | |
| 0900 – 1000 | **Conceptual Overviews** | Ballroom | |
|             | Scalable and portable HPC in Python using Parla and PyKokkos<br/> George Biros, University of Texas at Austin | | |
|             | Parsl - Python based workflow management<br/> Daniel S. Katz, Doug Friedel, University of Illinois Urbana-Champaign | | [slides](https://docs.google.com/presentation/d/1COX7K4QFI0SRhZpCSjHrNke3UfEd6qY9/edit?usp=sharing&ouid=110386689225117375572&rtpof=true&sd=true) |
|             | Pragmatic performance-portable solids and fluids with Ratel, libCEED, and PETSc<br/> Jed Brown, University of Colorado Boulder | | |
|             | CUnumeric and Legion<br/> Charlelie Laurent, Stanford University | | |
| 1000 - 1200 | **Code-alongs** | | |
|             | Scalable and portable HPC in Python using Parla and PyKokkos<br/> George Biros, University of Texas at Austin | Nevada | |
|             | Parsl - Python based workflow management<br/> Doug Friedel, Daniel S. Katz, University of Illinois Urbana-Champaign | Garden | [github.com/astro-friedel/Parsl_tutorial](https://github.com/astro-friedel/Parsl_tutorial) |
|             | Pragmatic performance-portable solids and fluids with Ratel, libCEED, and PETSc<br/> Jed Brown, University of Colorado Boulder | Arizona South | |
|             | CUnumeric and Legion<br/> Charlelie Laurent, Stanford University | Arizona North | |
| 1200 - 1300 | **Lunch break** | Ballroom | |
| 1300 – 1400 | **Conceptual Overviews** | Ballroom | |
|             | OpenCilk: A Modular and Extensible Software Infrastructure for Fast Task-Parallel Code<br/> Tao Schardl, Massachusetts Institute of Technology | | |
|             | MIRGE -- A lazy evaluation framework in Python<br/> Andreas Kloeckner, University of Illinois Urbana-Champaign | | |
|             | MPI Advance - Optimizations and Extensions to MPI<br/> Purushotham V. Bangalore, University of Alabama | | |
|             | Acceleration and Abstraction of Python based Monte Carlo Compute Kernels for Heterogeneous machines via Numba<br/> Joanna Piper Morgan, Oregon State University | | |
| 1400 - 1600 | **Code-alongs** | | |
|             | OpenCilk: A Modular and Extensible Software Infrastructure for Fast Task-Parallel Code<br/> Tao Schardl, Massachusetts Institute of Technology | Nevada | |
|             | MIRGE -- A lazy evaluation framework in Python<br/> Andreas Kloeckner, University of Illinois Urbana-Champaign | Garden | [github.com/illinois-ceesd/nuwest-mirge](https://github.com/illinois-ceesd/nuwest-mirge) |
|             | MPI Advance - Optimizations and Extensions to MPI<br/> Purushotham V. Bangalore, University of Alabama | Arizona South | |
|             | Acceleration and Abstraction of Python based Monte Carlo Compute Kernels for Heterogeneous machines via Numba<br/> Joanna Piper Morgan, Oregon State University | Arizona North | |
| 1600 - 1615 | **Concluding remarks**<br/> Luke Olson, University of Illinois Urbana-Champaingn | Ballroom | |
| 1700-1900   | (optional) social at Bow and Arrow<br/>Food truck on site; food and drinks are on your own.| | |

#### Related technologies and tools:

- PSAAP Centers: <https://psaap.llnl.gov/>
- Kokkos: <https://github.com/kokkos/kokkos>
- cuNumeric: <https://github.com/nv-legate/cunumeric>
- Legion: <https://legion.stanford.edu/>
- Parsl: <https://parsl-project.org/>
- Ratel: <https://gitlab.com/micromorph/ratel>
- libCEED: <https://libceed.org/>
- PETSc: <https://petsc.org/>
- Parla: <https://github.com/ut-parla/Parla.py>
- PyKokkos: <https://github.com/kokkos/pykokkos>
- Numba: <https://numba.pydata.org/>
- MIRGE-Com: <https://github.com/illinois-ceesd/mirgecom>
- MPI-advance: <https://github.com/mpi-advance>
- OpenCilk: <https://www.opencilk.org/>
